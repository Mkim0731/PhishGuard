1. Paper Selection
Choose a peer-reviewed research paper (conference or journal) relevant to your project.
The paper should include at least one available dataset with experimental or analytical results.
.
.
.
PAPER: -
https://www.researchgate.net/publication/377343024_DEPHIDES_Deep_Learning_Based_Phishing_Detection_System

CODE: -
https://github.com/ebubekirbbr/dephides/blob/main/README.md

Peer-Reviewed: - 
The Paper is peer-reviewed IEEE Access PP(99):1-1 and licensed by CC BY-NC-ND 4.0
.
.
.

2. Reproduction Plan
The research question you will reproduce.
The dataset, tools, or methodology required.
Potential challenges you foresee (e.g., missing details in the paper, computational constraints).
.
.
.
RESEARCH QUESTION: -  Can a character-level convolutional neural network (CNN) trained on raw URL text accurately 
                      classify phishing vs. benign URLs without relying on handcrafted features?
Dataset:
We will use the same dataset provided by the DEPHIDES authors, which contains approximately 5.2 million labeled URLs (phishing and legitimate).
This dataset is available publicly through the paper’s GitHub repository, making it easy to download and integrate.
https://github.com/ebubekirbbr/dephides/tree/main/dataset

Tools:
The DEPHIDES system was implemented using the following tools and libraries: -
Python 3.8
TensorFlow 2.2 for model training and evaluation
Keras (as part of TensorFlow) for model building
NumPy and Pandas for data manipulation
Matplotlib for plotting training performance
Scikit-learn for computing evaluation metrics such as precision, recall, and F1-score

Methodology:
We will reproduce the character-level Convolutional Neural Network (CNN) model described in the DEPHIDES paper. This model treats each 
URL as a textual input, applying Natural Language Processing (NLP) techniques commonly used in text classification tasks.

Specifically, the methodology involves:
Character-level tokenization of URLs: Each URL string is broken down into a sequence of characters.
Embedding layer: These characters are converted into dense vector representations, similar to how words are embedded in NLP models.
Convolutional layers: The model uses 1D CNNs to capture local patterns in the character sequences — akin to n-gram features in NLP.
Pooling layers: These reduce the dimensionality and highlight the most informative patterns.
Fully connected output layer: This layer performs binary classification to label each URL as phishing (1) or benign (0).

Challenges: - 
Computational Load: Training on the full 5M+ URL dataset may require a GPU and sufficient memory; subsampling may be necessary.
Version Compatibility: Slight differences in TensorFlow or library versions could affect results.
Hyperparameter Gaps: Some training details (e.g., learning rate, dropout) may need to be inferred from the code.
Random Variation: Without a fixed seed, results may vary slightly between runs.
.
.
.

3. Reproduction & Analysis
Reproduce the selected research question by:
Reimplementing the experiment.
Re-running analyses (if computational).
Reconstructing key figures/results (if applicable).
Compare your results with the original paper’s findings.
Discuss possible reasons for differences (e.g., parameter choices, data preprocessing).

ALL REPRODUCTION AND ANALYSIS IS IN A DIFFERENT FILE NAMED "Reproduction & Analysis" UNDER "Paper Reproduction Assignment".
.
.
.
Reproduction Output:

Final training accuracy: 99.39%

Final validation accuracy: 97.97%

Test accuracy: 97.95%

Strong generalization and no major overfitting issues.

Artifacts Saved:

model.h5 → Trained model.
tokenizer.pkl → Fitted character-level tokenizer.
training_curves.png → Accuracy & loss plots.
Classification report shows balanced precision/recall for both classes.

Model Architecture:
Char-level CNN with 3 Conv1D + MaxPooling layers.
~179K total parameters.
